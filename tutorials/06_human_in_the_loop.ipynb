{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387a8768",
   "metadata": {},
   "source": [
    "### åŸºç¤è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ LangChain 1.0 ä¸²æ¥æœ¬åœ° å¤§æ¨¡å‹\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:latest\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"What is the capital of the moon?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b48c4",
   "metadata": {},
   "source": [
    "### Human In The Loop: LangGraph Version Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# å®šç¾© State\n",
    "class State(TypedDict):\n",
    "    content: str        # LLM ç”Ÿæˆçš„å…§å®¹\n",
    "    decision: str       # äººé¡çš„æ±ºç­– ('approve', 'reject', 'continue'...)\n",
    "    feedback: str       # æ‹’çµ•æ™‚çš„ç†ç”± (å¯é¸)\n",
    "\n",
    "# ç¯€é»ï¼šLLM ç”Ÿæˆ (é€™è£¡ç°¡åŒ–æ¨¡æ“¬)\n",
    "def generator_node(state: State):\n",
    "    print(\"--- ğŸ¤– LLM æ­£åœ¨ç”Ÿæˆå…§å®¹ ---\")\n",
    "    # å¯¦éš›é€™è£¡æœƒå¯« llm.invoke(...)\n",
    "    # TODO: å¢åŠ ä½ æœ‰èˆˆè¶£çš„å…§å®¹\n",
    "    return {\"content\": \"é€™æ˜¯ LLM å¯«å¥½çš„åˆç¨¿ï¼Œè«‹å¯©æ ¸ã€‚\"}\n",
    "\n",
    "# ç¯€é»ï¼šäººé¡å¯©æ ¸ (é€™æ˜¯ä¸€å€‹ä¸­æ–·é»ï¼Œä»€éº¼éƒ½ä¸ç”¨åš)\n",
    "def human_review_node(state: State):\n",
    "    pass\n",
    "\n",
    "# é‚Šï¼šé‚è¼¯åˆ¤æ–·ï¼šæ ¹æ“šäººé¡çš„ decision æ±ºå®šä¸‹ä¸€æ­¥\n",
    "def router(state: State):\n",
    "    decision = state.get(\"decision\")\n",
    "    \n",
    "    if decision == \"reject\":\n",
    "        return \"rejected\"  # èµ°å‘æ‹’çµ•çš„çµå°¾\n",
    "    else:\n",
    "        return \"approved\"  # åŒ…å« approve å’Œ edit (è¦–ç‚ºé€šé)\n",
    "\n",
    "# ç¯€é»ï¼šå¾ŒçºŒè™•ç† (æ¨¡æ“¬)\n",
    "def approved_node(state: State):\n",
    "    print(f\"--- âœ… å…§å®¹å·²ç™¼å¸ƒ: {state['content']} ---\")\n",
    "    return\n",
    "\n",
    "def rejected_node(state: State):\n",
    "    print(f\"--- âŒ å…§å®¹è¢«æ‹’çµ•ï¼Œæµç¨‹çµ‚æ­¢ã€‚ç†ç”±: {state.get('feedback')} ---\")\n",
    "    return\n",
    "\n",
    "# --- å»ºæ§‹ Graph ---\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"generator\", generator_node)\n",
    "builder.add_node(\"human_review\", human_review_node)\n",
    "builder.add_node(\"approved\", approved_node)\n",
    "builder.add_node(\"rejected\", rejected_node)\n",
    "\n",
    "builder.set_entry_point(\"generator\")\n",
    "builder.add_edge(\"generator\", \"human_review\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"human_review\",\n",
    "    router,\n",
    "    {\n",
    "        \"approved\": \"approved\",\n",
    "        \"rejected\": \"rejected\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# HITL é‚è¼¯æµç¨‹:\n",
    "# (LLM ç”Ÿæˆ)\n",
    "#     |\n",
    "# [Human Review] <--- ğŸ›‘ Interrupt Here\n",
    "#     |\n",
    "#     +--- æ“ä½œ: Edit/Approve (update_state)\n",
    "#     |       |\n",
    "#     |       v\n",
    "#     |   [Router] --(Pass)--> [âœ… Approved Node]\n",
    "#     |\n",
    "#     +--- æ“ä½œ: Reject (update_state)\n",
    "#             |\n",
    "#             v\n",
    "#         [Router] --(Fail)--> [âŒ Rejected Node]\n",
    "\n",
    "graph = builder.compile(checkpointer=InMemorySaver(), interrupt_before=[\"human_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# è¨­å®šä¸€å€‹ Thread ID\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# åˆå§‹è¼¸å…¥\n",
    "input_to_stream = {\"content\": \"\", \"decision\": None}\n",
    "\n",
    "print(\"ğŸš€ æµç¨‹å•Ÿå‹•ï¼è«‹é—œæ³¨ä¸‹æ–¹çš„è¼¸å‡ºèˆ‡è¼¸å…¥æ¡†...\\n\")\n",
    "\n",
    "while True:\n",
    "    # è®“ Graph è·‘èµ·ä¾† (ç›´åˆ°é‡åˆ°ä¸­æ–·æˆ–çµæŸ)\n",
    "    for event in graph.stream(input_to_stream, config):\n",
    "        pass \n",
    "    \n",
    "    # æª¢æŸ¥ç›®å‰ç‹€æ…‹\n",
    "    snapshot = graph.get_state(config)\n",
    "\n",
    "    # print(f\"DEBUG: Next step is {snapshot.next}\")\n",
    "    \n",
    "    # å¦‚æœ next ç‚ºç©ºï¼Œä»£è¡¨æµç¨‹çµæŸ\n",
    "    if not snapshot.next:\n",
    "        print(\"\\nğŸ‰ æµç¨‹å·²å®Œæ•´çµæŸã€‚\")\n",
    "        break\n",
    "    \n",
    "    # æª¢æ¸¬æ˜¯å¦åœåœ¨æˆ‘å€‘é æœŸçš„ç¯€é»\n",
    "    if snapshot.next[0] == \"human_review\":\n",
    "        current_content = snapshot.values['content']\n",
    "        \n",
    "        print(f\"\\nğŸ›‘ [ä¸­æ–·] ç­‰å¾…äººé¡å¯©æ ¸ã€‚\")\n",
    "        print(f\"ğŸ“„ ç•¶å‰å…§å®¹: {current_content}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        \n",
    "        print(\"è«‹é¸æ“‡æ“ä½œï¼š\")\n",
    "        print(\"1. âœ… Approve (ç›´æ¥é€šé)\")\n",
    "        print(\"2. âœï¸ Edit (ä¿®æ”¹å…§å®¹å¾Œé€šé)\")\n",
    "        print(\"3. âŒ Reject (æ‹’çµ•ä¸¦å¡«å¯«ç†ç”±)\")\n",
    "        \n",
    "        user_choice = input(\"è«‹è¼¸å…¥é¸é … (1/2/3): \")\n",
    "        \n",
    "        # æ ¹æ“šä½ çš„è¼¸å…¥ï¼ŒåŸ·è¡Œä¸åŒçš„ update_state\n",
    "        if user_choice == \"1\":\n",
    "            print(\"--> ä½ é¸æ“‡äº† Approveã€‚\")\n",
    "            graph.update_state(config, {\"decision\": \"approve\"})\n",
    "            \n",
    "        elif user_choice == \"2\":\n",
    "            new_content = input(\"è«‹è¼¸å…¥ä¿®æ”¹å¾Œçš„å…§å®¹: \")\n",
    "            print(f\"--> ä½ é¸æ“‡äº† Editï¼Œå…§å®¹æ›´æ–°ç‚º: {new_content}\")\n",
    "            graph.update_state(config, {\n",
    "                \"content\": new_content, \n",
    "                \"decision\": \"approve\"\n",
    "            })\n",
    "            \n",
    "        elif user_choice == \"3\":\n",
    "            reason = input(\"è«‹è¼¸å…¥æ‹’çµ•ç†ç”±: \")\n",
    "            print(f\"--> ä½ é¸æ“‡äº† Rejectï¼Œç†ç”±: {reason}\")\n",
    "            graph.update_state(config, {\n",
    "                \"decision\": \"reject\",\n",
    "                \"feedback\": reason\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(\"âš ï¸ ç„¡æ•ˆè¼¸å…¥ï¼Œé è¨­è¦–ç‚º Approveã€‚\")\n",
    "            graph.update_state(config, {\"decision\": \"approve\"})\n",
    "            \n",
    "        # é—œéµï¼šå°‡ input è¨­ç‚º Noneï¼Œä»£è¡¨ Resume (ç¹¼çºŒåŸ·è¡Œ)\n",
    "        input_to_stream = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb73aff",
   "metadata": {},
   "source": [
    "### HITL Langchain 1.0 Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©å·¥å…·\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def get_weather(lat, lon):\n",
    "    \"\"\"\n",
    "    æŸ¥è©¢å³æ™‚å¤©æ°£çš„å‡½å¼ã€‚\n",
    "\n",
    "    :param lat: å¿…è¦åƒæ•¸ï¼Œæµ®é»æ•¸ (float) é¡å‹ï¼Œ\n",
    "                ç”¨ä¾†è¡¨ç¤ºè¦æŸ¥è©¢å¤©æ°£çš„å…·é«”ç·¯åº¦ã€‚\n",
    "\n",
    "    :param lon: å¿…è¦åƒæ•¸ï¼Œæµ®é»æ•¸ (float) é¡å‹ï¼Œ\n",
    "                ç”¨ä¾†è¡¨ç¤ºè¦æŸ¥è©¢å¤©æ°£çš„å…·é«”ç¶“åº¦ã€‚\n",
    "\n",
    "    :return: ä¾†è‡ª Open Metro API çš„å³æ™‚å¤©æ°£æŸ¥è©¢çµæœã€‚\n",
    "            (è«‹æ±‚ URL: https://api.open-meteo.com/v1/forecast)\n",
    "\n",
    "            å›å‚³çš„ç‰©ä»¶æ˜¯ã€Œè§£æå¾Œçš„ JSON æ ¼å¼ç‰©ä»¶ã€ï¼Œä¸¦ä»¥ã€Œå­—ä¸²ã€å½¢å¼è¡¨ç¤ºï¼Œ\n",
    "            å…¶ä¸­åŒ…å«äº†æ‰€æœ‰é‡è¦çš„å¤©æ°£è³‡è¨Šã€‚\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&hourly=temperature_2m\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    data = response.json()\n",
    "    temp = data['hourly']['temperature_2m'][0]\n",
    "    return {\"temperature\": temp}\n",
    "\n",
    "@tool\n",
    "def write_file(content: str, filename: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    å°‡æŒ‡å®šå…§å®¹å¯«å…¥æœ¬åœ°æ–‡ä»¶ã€‚\n",
    "\n",
    "    :param content: å¿…è¦åƒæ•¸ï¼Œå­—ä¸² (str) é¡å‹ï¼Œ\n",
    "                    ç”¨ä¾†è¡¨ç¤ºéœ€è¦å¯«å…¥æ–‡ä»¶çš„å…·é«”å…§å®¹ã€‚\n",
    "    :param filename: å¯é¸åƒæ•¸ï¼Œå­—ä¸² (str) é¡å‹ï¼Œ\n",
    "                    å»ºè­°æä¾›ç©ºå­—ä¸²ï¼Œå‰‡æœƒè‡ªå‹•ç”Ÿæˆä¸€å€‹æ–‡ä»¶åã€‚\n",
    "\n",
    "    :return: å¯«å…¥çµæœæç¤ºè³‡è¨Šã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename:\n",
    "            # âœ… å§‹çµ‚å…ˆå®šç¾©æ–‡ä»¶åï¼ˆé˜²æ­¢æœªç¶å®šè®Šé‡ï¼‰\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"output_{timestamp}.txt\"\n",
    "\n",
    "        # å¯«å…¥æ–‡ä»¶\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        abs_path = os.path.abspath(filename)\n",
    "        return f\"âœ… å·²æˆåŠŸå¯«å…¥æœ¬åœ°æ–‡ä»¶ï¼š{abs_path}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âŒ æ–‡ä»¶å¯«å…¥å¤±æ•—ï¼š{str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware \n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=ChatOllama(\n",
    "        model=\"qwen3:latest\",\n",
    "        temperature=0.5,\n",
    "    ),\n",
    "    tools=[write_file, get_weather],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware( \n",
    "            interrupt_on={\n",
    "                # \"write_file\": True,  # All decisions (approve, edit, reject) allowed\n",
    "                \"get_weather\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # No editing allowed\n",
    "            },\n",
    "            # Prefix for interrupt messages - combined with tool name and args to form the full message\n",
    "            # e.g., \"Tool execution pending approval: execute_sql with query='DELETE FROM...'\"\n",
    "            # Individual tools can override this by specifying a \"description\" in their interrupt config\n",
    "            description_prefix=\"Tool execution pending approval\",\n",
    "        ),\n",
    "    ],\n",
    "    # Human-in-the-loop requires checkpointing to handle interrupts.\n",
    "    # In production, use a persistent checkpointer like AsyncPostgresSaver.\n",
    "    checkpointer=InMemorySaver(),  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "import uuid\n",
    "\n",
    "# Human-in-the-loop leverages LangGraph's persistence layer.\n",
    "# You must provide a thread ID to associate the execution with a conversation thread,\n",
    "# so the conversation can be paused and resumed (as is needed for human review).\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}} \n",
    "# Run the graph until the interrupt is hit.\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"what is the weather in taipei?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interrupt contains the full HITL request with action_requests and review_configs\n",
    "print(result['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the process\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with approval decision\n",
    "result = agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [\n",
    "                    {\"type\": \"approve\"}, \n",
    "                ]}  # or \"edit\", \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce3c96",
   "metadata": {},
   "source": [
    "### ç·´ç¿’\n",
    "\n",
    "* HITL ä¿®æ”¹åƒæ•¸å…§å®¹\n",
    "* HITL äº’å‹•æ¨¡å¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
